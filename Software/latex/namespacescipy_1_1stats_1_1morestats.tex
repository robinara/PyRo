\hypertarget{namespacescipy_1_1stats_1_1morestats}{}\section{scipy.\+stats.\+morestats Namespace Reference}
\label{namespacescipy_1_1stats_1_1morestats}\index{scipy.\+stats.\+morestats@{scipy.\+stats.\+morestats}}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_afacc47108b5e9abae34bf101455f4596}{bayes\+\_\+mvs}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_aa623bea35a2cc0df27bfc3f0d8206fb2}{mvsdist}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a1f9ae31f25852b8042a8bee76c2d4f2b}{kstat}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_ad6abd69ba95df6a180701ff3bfd0566b}{kstatvar}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a0ce2313ec9f9874d21bba36d74c2b075}{probplot}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a3b440b836fcfd72740213ead34c4e947}{ppcc\+\_\+max}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_ab51988447490daeea0b39ac8d5172e07}{ppcc\+\_\+plot}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a72c28ea7d3a2cb0d22da1cdb4923e82e}{boxcox\+\_\+llf}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a9c746d8a1f0e8b4de8f4ff80cd86aedc}{boxcox}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_ac184ad145ff7a12af69b64044f075588}{boxcox\+\_\+normmax}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a208d9606d7c01574d651aefc3ab63e27}{boxcox\+\_\+normplot}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a7345bab19f49a0830910da93455ba6de}{shapiro}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a887883017dc52fa5feba58c70b1153fc}{anderson}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a577c1938c837ded86d281da702c48371}{anderson\+\_\+ksamp}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a3ebb07926c7a11f600d55537c885fc93}{ansari}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a99ab1f22fe2c9caa7d828f2234f7ebe4}{bartlett}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a0824020340ab066beb4b1448a821fda3}{levene}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a01b569f44155b742cfec656c5eb8b3fb}{binom\+\_\+test}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a44db8505680ecfe9b0380123227b45cc}{fligner}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a283d88b48c465d94790314978928591f}{mood}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a6db564dbaab9b636291a01534df2e66b}{wilcoxon}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a82acc7891c273aea5dd0a80e6aa06c4c}{pdf\+\_\+fromgamma}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_ac27db634417397cb6a1cb273c87353cb}{circmean}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a49ff3b4e6d6098f7ec7cc4574a8dc14f}{circvar}
\item 
def \hyperlink{namespacescipy_1_1stats_1_1morestats_a58e63b52c5f6dd694c176be740a32440}{circstd}
\end{DoxyCompactItemize}
\subsection*{Variables}
\begin{DoxyCompactItemize}
\item 
list \hyperlink{namespacescipy_1_1stats_1_1morestats_a4e1f06698420102c9803c6e61d1f61ca}{\+\_\+\+\_\+all\+\_\+\+\_\+}
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a6685b0049404f34263a74f571743ea20}{\+\_\+\+Avals\+\_\+norm} = array(\mbox{[}0.\+576, 0.\+656, 0.\+787, 0.\+918, 1.\+092\mbox{]})
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a8667e874e3198d418cb27417b6948166}{\+\_\+\+Avals\+\_\+expon} = array(\mbox{[}0.\+922, 1.\+078, 1.\+341, 1.\+606, 1.\+957\mbox{]})
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_abc2f7f99bb78a5601c155cceacd2e036}{\+\_\+\+Avals\+\_\+gumbel} = array(\mbox{[}0.\+474, 0.\+637, 0.\+757, 0.\+877, 1.\+038\mbox{]})
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a141be187dee0d0b2ed061081ceeb08f9}{\+\_\+\+Avals\+\_\+logistic} = array(\mbox{[}0.\+426, 0.\+563, 0.\+660, 0.\+769, 0.\+906, 1.\+010\mbox{]})
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a1ae693e1a4d206618c7a9de42f70e2ca}{w} = (y-\/xbar)
\begin{DoxyCompactList}\small\item\em def fixedsolve(th,xj,\+N)\+: val = stats.\+sum(xj)$\ast$1.0/\+N tmp = exp(-\/xj/th) term = sum(xj$\ast$tmp,axis=0) term /= sum(tmp,axis=0) return val -\/ term s = optimize.\+fixed\+\_\+point(fixedsolve, 1.\+0, args=(x,N),xtol=1e-\/5) xbar = -\/s$\ast$log(sum(exp(-\/x/s),axis=0)$\ast$1.0/\+N) \end{DoxyCompactList}\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_aa8cc3d21cb73a29266cecf589cc91372}{z} = distributions.\+gumbel\+\_\+l.\+cdf(\hyperlink{namespacescipy_1_1stats_1_1morestats_a1ae693e1a4d206618c7a9de42f70e2ca}{w})
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a9ec3d2a6dfa45c81743753af5649bb75}{sig} = array(\mbox{[}25,10,5,2.\+5,1\mbox{]})
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_ad38f5eb205317368cf1cae4038cc91fc}{critical} = around(\hyperlink{namespacescipy_1_1stats_1_1morestats_abc2f7f99bb78a5601c155cceacd2e036}{\+\_\+\+Avals\+\_\+gumbel} / (1.\+0 + 0.\+2/\hyperlink{vecuops_8cc_ac9f82fdb8cd289615247f897852ee5f2}{sqrt}(\hyperlink{polmisc_8c_a0240ac851181b84ac374872dc5434ee4}{N})),3)
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a6002aaa13e15af7a34f1c7a0c4f908e0}{i} = arange(1,\hyperlink{polmisc_8c_a0240ac851181b84ac374872dc5434ee4}{N}+1)
\item 
tuple \hyperlink{namespacescipy_1_1stats_1_1morestats_a9cb5458d19a10bb8b8bb0fc6c54aaef9}{S} = \hyperlink{vecsum_8cc_a208c561460f0b32ffa279a7ed7b7afa4}{sum}((2$\ast$\hyperlink{namespacescipy_1_1stats_1_1morestats_a6002aaa13e15af7a34f1c7a0c4f908e0}{i}-\/1.\+0)/\hyperlink{polmisc_8c_a0240ac851181b84ac374872dc5434ee4}{N}$\ast$(\hyperlink{vecuops_8cc_a9744da94c7846c49ff48444fde8d765f}{log}(\hyperlink{namespacescipy_1_1stats_1_1morestats_aa8cc3d21cb73a29266cecf589cc91372}{z})+\hyperlink{vecuops_8cc_a9744da94c7846c49ff48444fde8d765f}{log}(1-\/\hyperlink{namespacescipy_1_1stats_1_1morestats_aa8cc3d21cb73a29266cecf589cc91372}{z}\mbox{[}\+::-\/1\mbox{]})),axis=0)
\item 
\hyperlink{namespacescipy_1_1stats_1_1morestats_abc288edd80d387c4455e549e3d54b616}{A2} = -\/\hyperlink{polmisc_8c_a0240ac851181b84ac374872dc5434ee4}{N}-\/\hyperlink{namespacescipy_1_1stats_1_1morestats_a9cb5458d19a10bb8b8bb0fc6c54aaef9}{S}
\end{DoxyCompactItemize}


\subsection{Function Documentation}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a887883017dc52fa5feba58c70b1153fc}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!anderson@{anderson}}
\index{anderson@{anderson}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{anderson}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+anderson (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{dist = {\ttfamily '{\bf norm}'}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a887883017dc52fa5feba58c70b1153fc}
\begin{DoxyVerb}Anderson-Darling test for data coming from a particular distribution

The Anderson-Darling test is a modification of the Kolmogorov-
Smirnov test `kstest` for the null hypothesis that a sample is
drawn from a population that follows a particular distribution.
For the Anderson-Darling test, the critical values depend on
which distribution is being tested against.  This function works
for normal, exponential, logistic, or Gumbel (Extreme Value
Type I) distributions.

Parameters
----------
x : array_like
    array of sample data
dist : {'norm','expon','logistic','gumbel','extreme1'}, optional
    the type of distribution to test against.  The default is 'norm'
    and 'extreme1' is a synonym for 'gumbel'

Returns
-------
A2 : float
    The Anderson-Darling test statistic
critical : list
    The critical values for this distribution
sig : list
    The significance levels for the corresponding critical values
    in percents.  The function returns critical values for a
    differing set of significance levels depending on the
    distribution that is being tested against.

Notes
-----
Critical values provided are for the following significance levels:

normal/exponenential
    15%, 10%, 5%, 2.5%, 1%
logistic
    25%, 10%, 5%, 2.5%, 1%, 0.5%
Gumbel
    25%, 10%, 5%, 2.5%, 1%

If A2 is larger than these critical values then for the corresponding
significance level, the null hypothesis that the data come from the
chosen distribution can be rejected.

References
----------
.. [1] http://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm
.. [2] Stephens, M. A. (1974). EDF Statistics for Goodness of Fit and
       Some Comparisons, Journal of the American Statistical Association,
       Vol. 69, pp. 730-737.
.. [3] Stephens, M. A. (1976). Asymptotic Results for Goodness-of-Fit
       Statistics with Unknown Parameters, Annals of Statistics, Vol. 4,
       pp. 357-369.
.. [4] Stephens, M. A. (1977). Goodness of Fit for the Extreme Value
       Distribution, Biometrika, Vol. 64, pp. 583-588.
.. [5] Stephens, M. A. (1977). Goodness of Fit with Special Reference
       to Tests for Exponentiality , Technical Report No. 262,
       Department of Statistics, Stanford University, Stanford, CA.
.. [6] Stephens, M. A. (1979). Tests of Fit for the Logistic Distribution
       Based on the Empirical Distribution Function, Biometrika, Vol. 66,
       pp. 591-595.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a577c1938c837ded86d281da702c48371}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!anderson\+\_\+ksamp@{anderson\+\_\+ksamp}}
\index{anderson\+\_\+ksamp@{anderson\+\_\+ksamp}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{anderson\+\_\+ksamp}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+anderson\+\_\+ksamp (
\begin{DoxyParamCaption}
\item[{}]{samples, }
\item[{}]{midrank = {\ttfamily {\bf True}}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a577c1938c837ded86d281da702c48371}
\begin{DoxyVerb}The Anderson-Darling test for k-samples.

The k-sample Anderson-Darling test is a modification of the
one-sample Anderson-Darling test. It tests the null hypothesis
that k-samples are drawn from the same population without having
to specify the distribution function of that population. The
critical values depend on the number of samples.

Parameters
----------
samples : sequence of 1-D array_like
    Array of sample data in arrays.
midrank : bool, optional
    Type of Anderson-Darling test which is computed. Default
    (True) is the midrank test applicable to continuous and
    discrete populations. If False, the right side empirical
    distribution is used.

Returns
-------
A2 : float
    Normalized k-sample Anderson-Darling test statistic.
critical : array
    The critical values for significance levels 25%, 10%, 5%, 2.5%, 1%.
p : float
    An approximate significance level at which the null hypothesis for the
    provided samples can be rejected.

Raises
------
ValueError
    If less than 2 samples are provided, a sample is empty, or no
    distinct observations are in the samples.

See Also
--------
ks_2samp : 2 sample Kolmogorov-Smirnov test
anderson : 1 sample Anderson-Darling test

Notes
-----
[1]_ Defines three versions of the k-sample Anderson-Darling test:
one for continuous distributions and two for discrete
distributions, in which ties between samples may occur. The
default of this routine is to compute the version based on the
midrank empirical distribution function. This test is applicable
to continuous and discrete data. If midrank is set to False, the
right side empirical distribution is used for a test for discrete
data. According to [1]_, the two discrete test statistics differ
only slightly if a few collisions due to round-off errors occur in
the test not adjusted for ties between samples.

.. versionadded:: 0.14.0

References
----------
.. [1] Scholz, F. W and Stephens, M. A. (1987), K-Sample
       Anderson-Darling Tests, Journal of the American Statistical
       Association, Vol. 82, pp. 918-924.

Examples:
---------
>>> from scipy import stats
>>> np.random.seed(314159)

The null hypothesis that the two random samples come from the same
distribution can be rejected at the 5% level because the returned
test value is greater than the critical value for 5% (1.961) but
not at the 2.5% level. The interpolation gives an approximate
significance level of 3.1%:

>>> stats.anderson_ksamp([np.random.normal(size=50),
... np.random.normal(loc=0.5, size=30)])
(2.4615796189876105,
  array([ 0.325,  1.226,  1.961,  2.718,  3.752]),
  0.03134990135800783)


The null hypothesis cannot be rejected for three samples from an
identical distribution. The approximate p-value (87%) has to be
computed by extrapolation and may not be very accurate:

>>> stats.anderson_ksamp([np.random.normal(size=50),
... np.random.normal(size=30), np.random.normal(size=20)])
(-0.73091722665244196,
  array([ 0.44925884,  1.3052767 ,  1.9434184 ,  2.57696569,  3.41634856]),
  0.8789283903979661)
\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a3ebb07926c7a11f600d55537c885fc93}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!ansari@{ansari}}
\index{ansari@{ansari}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{ansari}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+ansari (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{y}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a3ebb07926c7a11f600d55537c885fc93}
\begin{DoxyVerb}Perform the Ansari-Bradley test for equal scale parameters

The Ansari-Bradley test is a non-parametric test for the equality
of the scale parameter of the distributions from which two
samples were drawn.

Parameters
----------
x, y : array_like
    arrays of sample data

Returns
-------
AB : float
    The Ansari-Bradley test statistic
p-value : float
    The p-value of the hypothesis test

See Also
--------
fligner : A non-parametric test for the equality of k variances
mood : A non-parametric test for the equality of two scale parameters

Notes
-----
The p-value given is exact when the sample sizes are both less than
55 and there are no ties, otherwise a normal approximation for the
p-value is used.

References
----------
.. [1] Sprent, Peter and N.C. Smeeton.  Applied nonparametric statistical
       methods.  3rd ed. Chapman and Hall/CRC. 2001.  Section 5.8.2.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a99ab1f22fe2c9caa7d828f2234f7ebe4}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!bartlett@{bartlett}}
\index{bartlett@{bartlett}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{bartlett}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+bartlett (
\begin{DoxyParamCaption}
\item[{}]{args}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a99ab1f22fe2c9caa7d828f2234f7ebe4}
\begin{DoxyVerb}Perform Bartlett's test for equal variances

Bartlett's test tests the null hypothesis that all input samples
are from populations with equal variances.  For samples
from significantly non-normal populations, Levene's test
`levene`_ is more robust.

Parameters
----------
sample1, sample2,... : array_like
    arrays of sample data.  May be different lengths.

Returns
-------
T : float
    The test statistic.
p-value : float
    The p-value of the test.

References
----------
.. [1]  http://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm

.. [2]  Snedecor, George W. and Cochran, William G. (1989), Statistical
          Methods, Eighth Edition, Iowa State University Press.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_afacc47108b5e9abae34bf101455f4596}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!bayes\+\_\+mvs@{bayes\+\_\+mvs}}
\index{bayes\+\_\+mvs@{bayes\+\_\+mvs}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{bayes\+\_\+mvs}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+bayes\+\_\+mvs (
\begin{DoxyParamCaption}
\item[{}]{data, }
\item[{}]{alpha = {\ttfamily 0.90}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_afacc47108b5e9abae34bf101455f4596}
\begin{DoxyVerb}Bayesian confidence intervals for the mean, var, and std.

Parameters
----------
data : array_like
    Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.
    Requires 2 or more data points.
alpha : float, optional
    Probability that the returned confidence interval contains
    the true parameter.

Returns
-------
mean_cntr, var_cntr, std_cntr : tuple
    The three results are for the mean, variance and standard deviation,
    respectively.  Each result is a tuple of the form::

        (center, (lower, upper))

    with `center` the mean of the conditional pdf of the value given the
    data, and `(lower, upper)` a confidence interval, centered on the
    median, containing the estimate to a probability `alpha`.

Notes
-----
Each tuple of mean, variance, and standard deviation estimates represent
the (center, (lower, upper)) with center the mean of the conditional pdf
of the value given the data and (lower, upper) is a confidence interval
centered on the median, containing the estimate to a probability
`alpha`.

Converts data to 1-D and assumes all data has the same mean and variance.
Uses Jeffrey's prior for variance and std.

Equivalent to tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))

References
----------
T.E. Oliphant, "A Bayesian perspective on estimating mean, variance, and
standard-deviation from data", http://hdl.handle.net/1877/438, 2006.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a01b569f44155b742cfec656c5eb8b3fb}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!binom\+\_\+test@{binom\+\_\+test}}
\index{binom\+\_\+test@{binom\+\_\+test}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{binom\+\_\+test}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+binom\+\_\+test (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{n = {\ttfamily None}, }
\item[{}]{p = {\ttfamily 0.5}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a01b569f44155b742cfec656c5eb8b3fb}
\begin{DoxyVerb}Perform a test that the probability of success is p.

This is an exact, two-sided test of the null hypothesis
that the probability of success in a Bernoulli experiment
is `p`.

Parameters
----------
x : integer or array_like
    the number of successes, or if x has length 2, it is the
    number of successes and the number of failures.
n : integer
    the number of trials.  This is ignored if x gives both the
    number of successes and failures
p : float, optional
    The hypothesized probability of success.  0 <= p <= 1. The
    default value is p = 0.5

Returns
-------
p-value : float
    The p-value of the hypothesis test

References
----------
.. [1] http://en.wikipedia.org/wiki/Binomial_test\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a9c746d8a1f0e8b4de8f4ff80cd86aedc}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!boxcox@{boxcox}}
\index{boxcox@{boxcox}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{boxcox}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+boxcox (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{lmbda = {\ttfamily None}, }
\item[{}]{alpha = {\ttfamily None}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a9c746d8a1f0e8b4de8f4ff80cd86aedc}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a72c28ea7d3a2cb0d22da1cdb4923e82e}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!boxcox\+\_\+llf@{boxcox\+\_\+llf}}
\index{boxcox\+\_\+llf@{boxcox\+\_\+llf}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{boxcox\+\_\+llf}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+boxcox\+\_\+llf (
\begin{DoxyParamCaption}
\item[{}]{lmb, }
\item[{}]{data}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a72c28ea7d3a2cb0d22da1cdb4923e82e}
\hypertarget{namespacescipy_1_1stats_1_1morestats_ac184ad145ff7a12af69b64044f075588}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!boxcox\+\_\+normmax@{boxcox\+\_\+normmax}}
\index{boxcox\+\_\+normmax@{boxcox\+\_\+normmax}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{boxcox\+\_\+normmax}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+boxcox\+\_\+normmax (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{brack = {\ttfamily (-\/2.0,~2.0}, }
\item[{}]{method = {\ttfamily 'pearsonr'}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_ac184ad145ff7a12af69b64044f075588}
\begin{DoxyVerb}Compute optimal Box-Cox transform parameter for input data.

Parameters
----------
x : array_like
    Input array.
brack : 2-tuple, optional
    The starting interval for a downhill bracket search with
    `optimize.brent`.  Note that this is in most cases not critical; the
    final result is allowed to be outside this bracket.
method : str, optional
    The method to determine the optimal transform parameter (`boxcox`
    ``lmbda`` parameter). Options are:

    'pearsonr'  (default)
        Maximizes the Pearson correlation coefficient between
        ``y = boxcox(x)`` and the expected values for ``y`` if `x` would be
        normally-distributed.

    'mle'
        Minimizes the log-likelihood `boxcox_llf`.  This is the method used
        in `boxcox`.

    'all'
        Use all optimization methods available, and return all results.
        Useful to compare different methods.

Returns
-------
maxlog : float or ndarray
    The optimal transform parameter found.  An array instead of a scalar
    for ``method='all'``.

See Also
--------
boxcox, boxcox_llf, boxcox_normplot

Examples
--------
>>> from scipy import stats
>>> import matplotlib.pyplot as plt
>>> np.random.seed(1234)  # make this example reproducible

Generate some data and determine optimal ``lmbda`` in various ways:

>>> x = stats.loggamma.rvs(5, size=30) + 5
>>> y, lmax_mle = stats.boxcox(x)
>>> lmax_pearsonr = stats.boxcox_normmax(x)

>>> lmax_mle
7.177...
>>> lmax_pearsonr
7.916...
>>> stats.boxcox_normmax(x, method='all')
array([ 7.91667384,  7.17718692])

>>> fig = plt.figure()
>>> ax = fig.add_subplot(111)
>>> stats.boxcox_normplot(x, -10, 10, plot=ax)
>>> ax.axvline(lmax_mle, color='r')
>>> ax.axvline(lmax_pearsonr, color='g', ls='--')

>>> plt.show()\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a208d9606d7c01574d651aefc3ab63e27}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!boxcox\+\_\+normplot@{boxcox\+\_\+normplot}}
\index{boxcox\+\_\+normplot@{boxcox\+\_\+normplot}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{boxcox\+\_\+normplot}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+boxcox\+\_\+normplot (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{la, }
\item[{}]{lb, }
\item[{}]{plot = {\ttfamily None}, }
\item[{}]{N = {\ttfamily 80}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a208d9606d7c01574d651aefc3ab63e27}
\begin{DoxyVerb}Compute parameters for a Box-Cox normality plot, optionally show it.

A Box-Cox normality plot shows graphically what the best transformation
parameter is to use in `boxcox` to obtain a distribution that is close
to normal.

Parameters
----------
x : array_like
    Input array.
la, lb : scalar
    The lower and upper bounds for the ``lmbda`` values to pass to `boxcox`
    for Box-Cox transformations.  These are also the limits of the
    horizontal axis of the plot if that is generated.
plot : object, optional
    If given, plots the quantiles and least squares fit.
    `plot` is an object that has to have methods "plot" and "text".
    The `matplotlib.pyplot` module or a Matplotlib Axes object can be used,
    or a custom object with the same methods.
    Default is None, which means that no plot is created.
N : int, optional
    Number of points on the horizontal axis (equally distributed from
    `la` to `lb`).

Returns
-------
lmbdas : ndarray
    The ``lmbda`` values for which a Box-Cox transform was done.
ppcc : ndarray
    Probability Plot Correlelation Coefficient, as obtained from `probplot`
    when fitting the Box-Cox transformed input `x` against a normal
    distribution.

See Also
--------
probplot, boxcox, boxcox_normmax, boxcox_llf, ppcc_max

Notes
-----
Even if `plot` is given, the figure is not shown or saved by
`boxcox_normplot`; ``plt.show()`` or ``plt.savefig('figname.png')``
should be used after calling `probplot`.

Examples
--------
>>> from scipy import stats
>>> import matplotlib.pyplot as plt

Generate some non-normally distributed data, and create a Box-Cox plot:

>>> x = stats.loggamma.rvs(5, size=500) + 5
>>> fig = plt.figure()
>>> ax = fig.add_subplot(111)
>>> stats.boxcox_normplot(x, -20, 20, plot=ax)

Determine and plot the optimal ``lmbda`` to transform ``x`` and plot it in
the same plot:

>>> _, maxlog = stats.boxcox(x)
>>> ax.axvline(maxlog, color='r')

>>> plt.show()\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_ac27db634417397cb6a1cb273c87353cb}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!circmean@{circmean}}
\index{circmean@{circmean}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{circmean}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+circmean (
\begin{DoxyParamCaption}
\item[{}]{samples, }
\item[{}]{high = {\ttfamily 2$\ast$pi}, }
\item[{}]{low = {\ttfamily 0}, }
\item[{}]{axis = {\ttfamily None}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_ac27db634417397cb6a1cb273c87353cb}
\begin{DoxyVerb}Compute the circular mean for samples in a range.

Parameters
----------
samples : array_like
    Input array.
high : float or int, optional
    High boundary for circular mean range.  Default is ``2*pi``.
low : float or int, optional
    Low boundary for circular mean range.  Default is 0.
axis : int, optional
    Axis along which means are computed.  The default is to compute
    the mean of the flattened array.

Returns
-------
circmean : float
    Circular mean.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a58e63b52c5f6dd694c176be740a32440}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!circstd@{circstd}}
\index{circstd@{circstd}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{circstd}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+circstd (
\begin{DoxyParamCaption}
\item[{}]{samples, }
\item[{}]{high = {\ttfamily 2$\ast$pi}, }
\item[{}]{low = {\ttfamily 0}, }
\item[{}]{axis = {\ttfamily None}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a58e63b52c5f6dd694c176be740a32440}
\begin{DoxyVerb}Compute the circular standard deviation for samples assumed to be in the
range [low to high].

Parameters
----------
samples : array_like
    Input array.
low : float or int, optional
    Low boundary for circular standard deviation range.  Default is 0.
high : float or int, optional
    High boundary for circular standard deviation range.
    Default is ``2*pi``.
axis : int, optional
    Axis along which standard deviations are computed.  The default is
    to compute the standard deviation of the flattened array.

Returns
-------
circstd : float
    Circular standard deviation.

Notes
-----
This uses a definition of circular standard deviation that in the limit of
small angles returns a number close to the 'linear' standard deviation.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a49ff3b4e6d6098f7ec7cc4574a8dc14f}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!circvar@{circvar}}
\index{circvar@{circvar}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{circvar}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+circvar (
\begin{DoxyParamCaption}
\item[{}]{samples, }
\item[{}]{high = {\ttfamily 2$\ast$pi}, }
\item[{}]{low = {\ttfamily 0}, }
\item[{}]{axis = {\ttfamily None}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a49ff3b4e6d6098f7ec7cc4574a8dc14f}
\begin{DoxyVerb}Compute the circular variance for samples assumed to be in a range

Parameters
----------
samples : array_like
    Input array.
low : float or int, optional
    Low boundary for circular variance range.  Default is 0.
high : float or int, optional
    High boundary for circular variance range.  Default is ``2*pi``.
axis : int, optional
    Axis along which variances are computed.  The default is to compute
    the variance of the flattened array.

Returns
-------
circvar : float
    Circular variance.

Notes
-----
This uses a definition of circular variance that in the limit of small
angles returns a number close to the 'linear' variance.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a44db8505680ecfe9b0380123227b45cc}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!fligner@{fligner}}
\index{fligner@{fligner}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{fligner}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+fligner (
\begin{DoxyParamCaption}
\item[{}]{args, }
\item[{}]{kwds}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a44db8505680ecfe9b0380123227b45cc}
\begin{DoxyVerb}Perform Fligner's test for equal variances.

Fligner's test tests the null hypothesis that all input samples
are from populations with equal variances.  Fligner's test is
non-parametric in contrast to Bartlett's test `bartlett` and
Levene's test `levene`.

Parameters
----------
sample1, sample2, ... : array_like
    arrays of sample data.  Need not be the same length
center : {'mean', 'median', 'trimmed'}, optional
    keyword argument controlling which function of the data
    is used in computing the test statistic.  The default
    is 'median'.
proportiontocut : float, optional
    When `center` is 'trimmed', this gives the proportion of data points
    to cut from each end. (See `scipy.stats.trim_mean`.)
    Default is 0.05.

Returns
-------
Xsq : float
    the test statistic
p-value : float
    the p-value for the hypothesis test

Notes
-----
As with Levene's test there are three variants
of Fligner's test that differ by the measure of central
tendency used in the test.  See `levene` for more information.

References
----------
.. [1] http://www.stat.psu.edu/~bgl/center/tr/TR993.ps

.. [2] Fligner, M.A. and Killeen, T.J. (1976). Distribution-free two-sample
       tests for scale. 'Journal of the American Statistical Association.'
       71(353), 210-213.\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a1f9ae31f25852b8042a8bee76c2d4f2b}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!kstat@{kstat}}
\index{kstat@{kstat}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{kstat}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+kstat (
\begin{DoxyParamCaption}
\item[{}]{data, }
\item[{}]{n = {\ttfamily 2}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a1f9ae31f25852b8042a8bee76c2d4f2b}
\begin{DoxyVerb}Return the nth k-statistic (1<=n<=4 so far).

The nth k-statistic is the unique symmetric unbiased estimator of the nth
cumulant kappa_n.

Parameters
----------
data : array_like
    Input array.
n : int, {1, 2, 3, 4}, optional
    Default is equal to 2.

Returns
-------
kstat : float
    The nth k-statistic.

See Also
--------
kstatvar: Returns an unbiased estimator of the variance of the k-statistic.

Notes
-----
The cumulants are related to central moments but are specifically defined
using a power series expansion of the logarithm of the characteristic
function (which is the Fourier transform of the PDF).
In particular let phi(t) be the characteristic function, then::

    ln phi(t) = > kappa_n (it)^n / n!    (sum from n=0 to inf)

The first few cumulants (kappa_n)  in terms of central moments (mu_n) are::

    kappa_1 = mu_1
    kappa_2 = mu_2
    kappa_3 = mu_3
    kappa_4 = mu_4 - 3*mu_2**2
    kappa_5 = mu_5 - 10*mu_2 * mu_3

References
----------
http://mathworld.wolfram.com/k-Statistic.html

http://mathworld.wolfram.com/Cumulant.html\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_ad6abd69ba95df6a180701ff3bfd0566b}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!kstatvar@{kstatvar}}
\index{kstatvar@{kstatvar}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{kstatvar}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+kstatvar (
\begin{DoxyParamCaption}
\item[{}]{data, }
\item[{}]{n = {\ttfamily 2}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_ad6abd69ba95df6a180701ff3bfd0566b}
\begin{DoxyVerb}Returns an unbiased estimator of the variance of the k-statistic.

See `kstat` for more details of the k-statistic.

Parameters
----------
data : array_like
    Input array.
n : int, {1, 2}, optional
    Default is equal to 2.

Returns
-------
kstatvar : float
    The nth k-statistic variance.

See Also
--------
kstat\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a0824020340ab066beb4b1448a821fda3}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!levene@{levene}}
\index{levene@{levene}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{levene}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+levene (
\begin{DoxyParamCaption}
\item[{}]{args, }
\item[{}]{kwds}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a0824020340ab066beb4b1448a821fda3}
\begin{DoxyVerb}Perform Levene test for equal variances.

The Levene test tests the null hypothesis that all input samples
are from populations with equal variances.  Levene's test is an
alternative to Bartlett's test `bartlett` in the case where
there are significant deviations from normality.

Parameters
----------
sample1, sample2, ... : array_like
    The sample data, possibly with different lengths
center : {'mean', 'median', 'trimmed'}, optional
    Which function of the data to use in the test.  The default
    is 'median'.
proportiontocut : float, optional
    When `center` is 'trimmed', this gives the proportion of data points
    to cut from each end. (See `scipy.stats.trim_mean`.)
    Default is 0.05.

Returns
-------
W : float
    The test statistic.
p-value : float
    The p-value for the test.

Notes
-----
Three variations of Levene's test are possible.  The possibilities
and their recommended usages are:

  * 'median' : Recommended for skewed (non-normal) distributions>
  * 'mean' : Recommended for symmetric, moderate-tailed distributions.
  * 'trimmed' : Recommended for heavy-tailed distributions.

References
----------
.. [1]  http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm
.. [2]   Levene, H. (1960). In Contributions to Probability and Statistics:
           Essays in Honor of Harold Hotelling, I. Olkin et al. eds.,
           Stanford University Press, pp. 278-292.
.. [3]  Brown, M. B. and Forsythe, A. B. (1974), Journal of the American
          Statistical Association, 69, 364-367\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a283d88b48c465d94790314978928591f}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!mood@{mood}}
\index{mood@{mood}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{mood}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+mood (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{y, }
\item[{}]{axis = {\ttfamily 0}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a283d88b48c465d94790314978928591f}
\begin{DoxyVerb}Perform Mood's test for equal scale parameters.

Mood's two-sample test for scale parameters is a non-parametric
test for the null hypothesis that two samples are drawn from the
same distribution with the same scale parameter.

Parameters
----------
x, y : array_like
    Arrays of sample data.
axis: int, optional
    The axis along which the samples are tested.  `x` and `y` can be of
    different length along `axis`.
    If `axis` is None, `x` and `y` are flattened and the test is done on
    all values in the flattened arrays.

Returns
-------
z : scalar or ndarray
    The z-score for the hypothesis test.  For 1-D inputs a scalar is
    returned;
p-value : scalar ndarray
    The p-value for the hypothesis test.

See Also
--------
fligner : A non-parametric test for the equality of k variances
ansari : A non-parametric test for the equality of 2 variances
bartlett : A parametric test for equality of k variances in normal samples
levene : A parametric test for equality of k variances

Notes
-----
The data are assumed to be drawn from probability distributions ``f(x)``
and ``f(x/s) / s`` respectively, for some probability density function f.
The null hypothesis is that ``s == 1``.

For multi-dimensional arrays, if the inputs are of shapes
``(n0, n1, n2, n3)``  and ``(n0, m1, n2, n3)``, then if ``axis=1``, the
resulting z and p values will have shape ``(n0, n2, n3)``.  Note that
``n1`` and ``m1`` don't have to be equal, but the other dimensions do.

Examples
--------
>>> from scipy import stats
>>> x2 = np.random.randn(2, 45, 6, 7)
>>> x1 = np.random.randn(2, 30, 6, 7)
>>> z, p = stats.mood(x1, x2, axis=1)
>>> p.shape
(2, 6, 7)

Find the number of points where the difference in scale is not significant:

>>> (p > 0.1).sum()
74

Perform the test with different scales:

>>> x1 = np.random.randn(2, 30)
>>> x2 = np.random.randn(2, 35) * 10.0
>>> stats.mood(x1, x2, axis=1)
(array([-5.84332354, -5.6840814 ]), array([5.11694980e-09, 1.31517628e-08]))\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_aa623bea35a2cc0df27bfc3f0d8206fb2}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!mvsdist@{mvsdist}}
\index{mvsdist@{mvsdist}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{mvsdist}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+mvsdist (
\begin{DoxyParamCaption}
\item[{}]{data}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_aa623bea35a2cc0df27bfc3f0d8206fb2}
\begin{DoxyVerb}'Frozen' distributions for mean, variance, and standard deviation of data.

Parameters
----------
data : array_like
    Input array. Converted to 1-D using ravel.
    Requires 2 or more data-points.

Returns
-------
mdist : "frozen" distribution object
    Distribution object representing the mean of the data
vdist : "frozen" distribution object
    Distribution object representing the variance of the data
sdist : "frozen" distribution object
    Distribution object representing the standard deviation of the data

Notes
-----
The return values from bayes_mvs(data) is equivalent to
``tuple((x.mean(), x.interval(0.90)) for x in mvsdist(data))``.

In other words, calling ``<dist>.mean()`` and ``<dist>.interval(0.90)``
on the three distribution objects returned from this function will give
the same results that are returned from `bayes_mvs`.

Examples
--------
>>> from scipy.stats import mvsdist
>>> data = [6, 9, 12, 7, 8, 8, 13]
>>> mean, var, std = mvsdist(data)

We now have frozen distribution objects "mean", "var" and "std" that we can
examine:

>>> mean.mean()
9.0
>>> mean.interval(0.95)
(6.6120585482655692, 11.387941451734431)
>>> mean.std()
1.1952286093343936\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a82acc7891c273aea5dd0a80e6aa06c4c}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!pdf\+\_\+fromgamma@{pdf\+\_\+fromgamma}}
\index{pdf\+\_\+fromgamma@{pdf\+\_\+fromgamma}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{pdf\+\_\+fromgamma}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+pdf\+\_\+fromgamma (
\begin{DoxyParamCaption}
\item[{}]{g1, }
\item[{}]{g2, }
\item[{}]{g3 = {\ttfamily 0.0}, }
\item[{}]{g4 = {\ttfamily None}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a82acc7891c273aea5dd0a80e6aa06c4c}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a3b440b836fcfd72740213ead34c4e947}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!ppcc\+\_\+max@{ppcc\+\_\+max}}
\index{ppcc\+\_\+max@{ppcc\+\_\+max}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{ppcc\+\_\+max}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+ppcc\+\_\+max (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{brack = {\ttfamily (0.0,1.0}, }
\item[{}]{dist = {\ttfamily 'tukeylambda'}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a3b440b836fcfd72740213ead34c4e947}
\begin{DoxyVerb}Returns the shape parameter that maximizes the probability plot
correlation coefficient for the given data to a one-parameter
family of distributions.

See also ppcc_plot
\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_ab51988447490daeea0b39ac8d5172e07}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!ppcc\+\_\+plot@{ppcc\+\_\+plot}}
\index{ppcc\+\_\+plot@{ppcc\+\_\+plot}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{ppcc\+\_\+plot}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+ppcc\+\_\+plot (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{a, }
\item[{}]{b, }
\item[{}]{dist = {\ttfamily 'tukeylambda'}, }
\item[{}]{plot = {\ttfamily None}, }
\item[{}]{N = {\ttfamily 80}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_ab51988447490daeea0b39ac8d5172e07}
\begin{DoxyVerb}Returns (shape, ppcc), and optionally plots shape vs. ppcc
(probability plot correlation coefficient) as a function of shape
parameter for a one-parameter family of distributions from shape
value a to b.

See also ppcc_max
\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a0ce2313ec9f9874d21bba36d74c2b075}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!probplot@{probplot}}
\index{probplot@{probplot}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{probplot}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+probplot (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{sparams = {\ttfamily ()}, }
\item[{}]{dist = {\ttfamily '{\bf norm}'}, }
\item[{}]{fit = {\ttfamily {\bf True}}, }
\item[{}]{plot = {\ttfamily None}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a0ce2313ec9f9874d21bba36d74c2b075}
\begin{DoxyVerb}Calculate quantiles for a probability plot, and optionally show the plot.

Generates a probability plot of sample data against the quantiles of a
specified theoretical distribution (the normal distribution by default).
`probplot` optionally calculates a best-fit line for the data and plots the
results using Matplotlib or a given plot function.

Parameters
----------
x : array_like
    Sample/response data from which `probplot` creates the plot.
sparams : tuple, optional
    Distribution-specific shape parameters (shape parameters plus location
    and scale).
dist : str or stats.distributions instance, optional
    Distribution or distribution function name. The default is 'norm' for a
    normal probability plot.  Objects that look enough like a
    stats.distributions instance (i.e. they have a ``ppf`` method) are also
    accepted.
fit : bool, optional
    Fit a least-squares regression (best-fit) line to the sample data if
    True (default).
plot : object, optional
    If given, plots the quantiles and least squares fit.
    `plot` is an object that has to have methods "plot" and "text".
    The `matplotlib.pyplot` module or a Matplotlib Axes object can be used,
    or a custom object with the same methods.
    Default is None, which means that no plot is created.

Returns
-------
(osm, osr) : tuple of ndarrays
    Tuple of theoretical quantiles (osm, or order statistic medians) and
    ordered responses (osr).  `osr` is simply sorted input `x`.
    For details on how `osm` is calculated see the Notes section.
(slope, intercept, r) : tuple of floats, optional
    Tuple  containing the result of the least-squares fit, if that is
    performed by `probplot`. `r` is the square root of the coefficient of
    determination.  If ``fit=False`` and ``plot=None``, this tuple is not
    returned.

Notes
-----
Even if `plot` is given, the figure is not shown or saved by `probplot`;
``plt.show()`` or ``plt.savefig('figname.png')`` should be used after
calling `probplot`.

`probplot` generates a probability plot, which should not be confused with
a Q-Q or a P-P plot.  Statsmodels has more extensive functionality of this
type, see ``statsmodels.api.ProbPlot``.

The formula used for the theoretical quantiles (horizontal axis of the
probability plot) is Filliben's estimate::

    quantiles = dist.ppf(val), for

            0.5**(1/n),                  for i = n
      val = (i - 0.3175) / (n + 0.365),  for i = 2, ..., n-1
            1 - 0.5**(1/n),              for i = 1

where ``i`` indicates the i-th ordered value and ``n`` is the total number
of values.

Examples
--------
>>> from scipy import stats
>>> import matplotlib.pyplot as plt
>>> nsample = 100
>>> np.random.seed(7654321)

A t distribution with small degrees of freedom:

>>> ax1 = plt.subplot(221)
>>> x = stats.t.rvs(3, size=nsample)
>>> res = stats.probplot(x, plot=plt)

A t distribution with larger degrees of freedom:

>>> ax2 = plt.subplot(222)
>>> x = stats.t.rvs(25, size=nsample)
>>> res = stats.probplot(x, plot=plt)

A mixture of two normal distributions with broadcasting:

>>> ax3 = plt.subplot(223)
>>> x = stats.norm.rvs(loc=[0,5], scale=[1,1.5],
...                    size=(nsample/2.,2)).ravel()
>>> res = stats.probplot(x, plot=plt)

A standard normal distribution:

>>> ax4 = plt.subplot(224)
>>> x = stats.norm.rvs(loc=0, scale=1, size=nsample)
>>> res = stats.probplot(x, plot=plt)

Produce a new figure with a loggamma distribution, using the ``dist`` and
``sparams`` keywords:

>>> fig = plt.figure()
>>> ax = fig.add_subplot(111)
>>> x = stats.loggamma.rvs(c=2.5, size=500)
>>> stats.probplot(x, dist=stats.loggamma, sparams=(2.5,), plot=ax)
>>> ax.set_title("Probplot for loggamma dist with shape parameter 2.5")

Show the results with Matplotlib:

>>> plt.show()\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a7345bab19f49a0830910da93455ba6de}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!shapiro@{shapiro}}
\index{shapiro@{shapiro}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{shapiro}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+shapiro (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{a = {\ttfamily None}, }
\item[{}]{reta = {\ttfamily {\bf False}}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a7345bab19f49a0830910da93455ba6de}
\begin{DoxyVerb}Perform the Shapiro-Wilk test for normality.

The Shapiro-Wilk test tests the null hypothesis that the
data was drawn from a normal distribution.

Parameters
----------
x : array_like
    Array of sample data.
a : array_like, optional
    Array of internal parameters used in the calculation.  If these
    are not given, they will be computed internally.  If x has length
    n, then a must have length n/2.
reta : bool, optional
    Whether or not to return the internally computed a values.  The
    default is False.

Returns
-------
W : float
    The test statistic.
p-value : float
    The p-value for the hypothesis test.
a : array_like, optional
    If `reta` is True, then these are the internally computed "a"
    values that may be passed into this function on future calls.

See Also
--------
anderson : The Anderson-Darling test for normality

References
----------
.. [1] http://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\end{DoxyVerb}
 \hypertarget{namespacescipy_1_1stats_1_1morestats_a6db564dbaab9b636291a01534df2e66b}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!wilcoxon@{wilcoxon}}
\index{wilcoxon@{wilcoxon}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{wilcoxon}]{\setlength{\rightskip}{0pt plus 5cm}def scipy.\+stats.\+morestats.\+wilcoxon (
\begin{DoxyParamCaption}
\item[{}]{x, }
\item[{}]{y = {\ttfamily None}, }
\item[{}]{zero\+\_\+method = {\ttfamily \char`\"{}wilcox\char`\"{}}, }
\item[{}]{correction = {\ttfamily {\bf False}}}
\end{DoxyParamCaption}
)}\label{namespacescipy_1_1stats_1_1morestats_a6db564dbaab9b636291a01534df2e66b}
\begin{DoxyVerb}Calculate the Wilcoxon signed-rank test.

The Wilcoxon signed-rank test tests the null hypothesis that two
related paired samples come from the same distribution. In particular,
it tests whether the distribution of the differences x - y is symmetric
about zero. It is a non-parametric version of the paired T-test.

Parameters
----------
x : array_like
    The first set of measurements.
y : array_like, optional
    The second set of measurements.  If `y` is not given, then the `x`
    array is considered to be the differences between the two sets of
    measurements.
zero_method : string, {"pratt", "wilcox", "zsplit"}, optional
    "pratt":
        Pratt treatment: includes zero-differences in the ranking process
        (more conservative)
    "wilcox":
        Wilcox treatment: discards all zero-differences
    "zsplit":
        Zero rank split: just like Pratt, but spliting the zero rank
        between positive and negative ones
correction : bool, optional
    If True, apply continuity correction by adjusting the Wilcoxon rank
    statistic by 0.5 towards the mean value when computing the
    z-statistic.  Default is False.

Returns
-------
T : float
    The sum of the ranks of the differences above or below zero, whichever
    is smaller.
p-value : float
    The two-sided p-value for the test.

Notes
-----
Because the normal approximation is used for the calculations, the
samples used should be large.  A typical rule is to require that
n > 20.

References
----------
.. [1] http://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\end{DoxyVerb}
 

\subsection{Variable Documentation}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a4e1f06698420102c9803c6e61d1f61ca}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!\+\_\+\+\_\+all\+\_\+\+\_\+@{\+\_\+\+\_\+all\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+all\+\_\+\+\_\+@{\+\_\+\+\_\+all\+\_\+\+\_\+}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{\+\_\+\+\_\+all\+\_\+\+\_\+}]{\setlength{\rightskip}{0pt plus 5cm}list scipy.\+stats.\+morestats.\+\_\+\+\_\+all\+\_\+\+\_\+}\label{namespacescipy_1_1stats_1_1morestats_a4e1f06698420102c9803c6e61d1f61ca}
{\bfseries Initial value\+:}
\begin{DoxyCode}
1 = [\textcolor{stringliteral}{'mvsdist'},
2            \textcolor{stringliteral}{'bayes\_mvs'}, \textcolor{stringliteral}{'kstat'}, \textcolor{stringliteral}{'kstatvar'}, \textcolor{stringliteral}{'probplot'}, \textcolor{stringliteral}{'ppcc\_max'}, \textcolor{stringliteral}{'ppcc\_plot'},
3            \textcolor{stringliteral}{'boxcox\_llf'}, \textcolor{stringliteral}{'boxcox'}, \textcolor{stringliteral}{'boxcox\_normmax'}, \textcolor{stringliteral}{'boxcox\_normplot'},
4            \textcolor{stringliteral}{'shapiro'}, \textcolor{stringliteral}{'anderson'}, \textcolor{stringliteral}{'ansari'}, \textcolor{stringliteral}{'bartlett'}, \textcolor{stringliteral}{'levene'}, \textcolor{stringliteral}{'binom\_test'},
5            \textcolor{stringliteral}{'fligner'}, \textcolor{stringliteral}{'mood'}, \textcolor{stringliteral}{'wilcoxon'},
6            \textcolor{stringliteral}{'pdf\_fromgamma'}, \textcolor{stringliteral}{'circmean'}, \textcolor{stringliteral}{'circvar'}, \textcolor{stringliteral}{'circstd'}, \textcolor{stringliteral}{'anderson\_ksamp'}
7            ]
\end{DoxyCode}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a8667e874e3198d418cb27417b6948166}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!\+\_\+\+Avals\+\_\+expon@{\+\_\+\+Avals\+\_\+expon}}
\index{\+\_\+\+Avals\+\_\+expon@{\+\_\+\+Avals\+\_\+expon}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{\+\_\+\+Avals\+\_\+expon}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+\_\+\+Avals\+\_\+expon = array(\mbox{[}0.\+922, 1.\+078, 1.\+341, 1.\+606, 1.\+957\mbox{]})}\label{namespacescipy_1_1stats_1_1morestats_a8667e874e3198d418cb27417b6948166}
\hypertarget{namespacescipy_1_1stats_1_1morestats_abc2f7f99bb78a5601c155cceacd2e036}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!\+\_\+\+Avals\+\_\+gumbel@{\+\_\+\+Avals\+\_\+gumbel}}
\index{\+\_\+\+Avals\+\_\+gumbel@{\+\_\+\+Avals\+\_\+gumbel}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{\+\_\+\+Avals\+\_\+gumbel}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+\_\+\+Avals\+\_\+gumbel = array(\mbox{[}0.\+474, 0.\+637, 0.\+757, 0.\+877, 1.\+038\mbox{]})}\label{namespacescipy_1_1stats_1_1morestats_abc2f7f99bb78a5601c155cceacd2e036}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a141be187dee0d0b2ed061081ceeb08f9}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!\+\_\+\+Avals\+\_\+logistic@{\+\_\+\+Avals\+\_\+logistic}}
\index{\+\_\+\+Avals\+\_\+logistic@{\+\_\+\+Avals\+\_\+logistic}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{\+\_\+\+Avals\+\_\+logistic}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+\_\+\+Avals\+\_\+logistic = array(\mbox{[}0.\+426, 0.\+563, 0.\+660, 0.\+769, 0.\+906, 1.\+010\mbox{]})}\label{namespacescipy_1_1stats_1_1morestats_a141be187dee0d0b2ed061081ceeb08f9}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a6685b0049404f34263a74f571743ea20}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!\+\_\+\+Avals\+\_\+norm@{\+\_\+\+Avals\+\_\+norm}}
\index{\+\_\+\+Avals\+\_\+norm@{\+\_\+\+Avals\+\_\+norm}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{\+\_\+\+Avals\+\_\+norm}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+\_\+\+Avals\+\_\+norm = array(\mbox{[}0.\+576, 0.\+656, 0.\+787, 0.\+918, 1.\+092\mbox{]})}\label{namespacescipy_1_1stats_1_1morestats_a6685b0049404f34263a74f571743ea20}
\hypertarget{namespacescipy_1_1stats_1_1morestats_abc288edd80d387c4455e549e3d54b616}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!A2@{A2}}
\index{A2@{A2}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{A2}]{\setlength{\rightskip}{0pt plus 5cm}scipy.\+stats.\+morestats.\+A2 = -\/{\bf N}-\/{\bf S}}\label{namespacescipy_1_1stats_1_1morestats_abc288edd80d387c4455e549e3d54b616}
\hypertarget{namespacescipy_1_1stats_1_1morestats_ad38f5eb205317368cf1cae4038cc91fc}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!critical@{critical}}
\index{critical@{critical}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{critical}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+critical = around({\bf \+\_\+\+Avals\+\_\+gumbel} / (1.\+0 + 0.\+2/{\bf sqrt}({\bf N})),3)}\label{namespacescipy_1_1stats_1_1morestats_ad38f5eb205317368cf1cae4038cc91fc}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a6002aaa13e15af7a34f1c7a0c4f908e0}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!i@{i}}
\index{i@{i}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{i}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+i = arange(1,{\bf N}+1)}\label{namespacescipy_1_1stats_1_1morestats_a6002aaa13e15af7a34f1c7a0c4f908e0}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a9cb5458d19a10bb8b8bb0fc6c54aaef9}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!S@{S}}
\index{S@{S}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{S}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+S = {\bf sum}((2$\ast${\bf i}-\/1.\+0)/{\bf N}$\ast$({\bf log}({\bf z})+{\bf log}(1-\/{\bf z}\mbox{[}\+::-\/1\mbox{]})),axis=0)}\label{namespacescipy_1_1stats_1_1morestats_a9cb5458d19a10bb8b8bb0fc6c54aaef9}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a9ec3d2a6dfa45c81743753af5649bb75}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!sig@{sig}}
\index{sig@{sig}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{sig}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+sig = array(\mbox{[}25,10,5,2.\+5,1\mbox{]})}\label{namespacescipy_1_1stats_1_1morestats_a9ec3d2a6dfa45c81743753af5649bb75}
\hypertarget{namespacescipy_1_1stats_1_1morestats_a1ae693e1a4d206618c7a9de42f70e2ca}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!w@{w}}
\index{w@{w}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{w}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+w = (y-\/xbar)}\label{namespacescipy_1_1stats_1_1morestats_a1ae693e1a4d206618c7a9de42f70e2ca}


def fixedsolve(th,xj,\+N)\+: val = stats.\+sum(xj)$\ast$1.0/\+N tmp = exp(-\/xj/th) term = sum(xj$\ast$tmp,axis=0) term /= sum(tmp,axis=0) return val -\/ term s = optimize.\+fixed\+\_\+point(fixedsolve, 1.\+0, args=(x,N),xtol=1e-\/5) xbar = -\/s$\ast$log(sum(exp(-\/x/s),axis=0)$\ast$1.0/\+N) 

\hypertarget{namespacescipy_1_1stats_1_1morestats_aa8cc3d21cb73a29266cecf589cc91372}{}\index{scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}!z@{z}}
\index{z@{z}!scipy\+::stats\+::morestats@{scipy\+::stats\+::morestats}}
\subsubsection[{z}]{\setlength{\rightskip}{0pt plus 5cm}tuple scipy.\+stats.\+morestats.\+z = distributions.\+gumbel\+\_\+l.\+cdf({\bf w})}\label{namespacescipy_1_1stats_1_1morestats_aa8cc3d21cb73a29266cecf589cc91372}
